{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywen2\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import scipy.stats as ss\n",
    "import csv\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import glob\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARACIÓN ENTRE LA CARPETA PACIENTES Y EL CSV PACIENTES_PROGRESORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONTENIDO**:\n",
    "    \n",
    "* En la carpeta **pacientes** tengo 1794 ficheros nombrados con el número de historia de cada paciente, cada fichero contiene las mediciones que se han hecho a cada paciente en X revisiones.    \n",
    "\n",
    "* En el csv **pacientes_progresores** tengo dos columnas. La primera columna es el número de historia clínica del pacientes y la segunda columna toma valores 0 o 1, siendo el 0 pacientes no progresores y el 1 pacientes progresores.\n",
    "\n",
    "**OBJETIVO**:\n",
    "\n",
    "* El primer paso es detectar que pacientes de mi carpeta **pacientes** se encuentra en el csv **pacientes_progresores**, ya que el número de pacientes en la carpeta es mayor que en el csv.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PASOS**:\n",
    "\n",
    "* Almaceno en una lista llamada pacientes_independientes todos los ficheros de la carpeta **pacientes**\n",
    "* Creo una lista llamada pacientes_progresores a partir del csv **pacientes_progresores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#contenido = os.listdir('C:/Users/ywen2/Desktop/URJC/TFG/TFG_GITHUB/ddbb/pacientes')\n",
    "contenido = os.listdir('../ddbb/pacientes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_id_indep =  [item.replace(\".csv\", \"\") for item in contenido] #Elimino .csv para quedarme solo el Nº de historia y poder \n",
    "#comparar mas fácilmente con el csv pacientes_progresores\n",
    "\n",
    "#Convierto la lista a CSV\n",
    "pacientes_independientes = pd.DataFrame(lista_id_indep, columns=[\"Pacientes\"])\n",
    "pacientes_independientes.to_csv('pacientes_indep.csv', index=False)\n",
    "\n",
    "#Convierto el CSV a una lista nuevamente\n",
    "df_independientes = pd.read_csv('pacientes_indep.csv').fillna(0)\n",
    "pacientes_independientes = df_independientes.iloc[:,0]\n",
    "pacientes_independientes = list(pacientes_independientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo una lista a partir del csv: pacientes_progresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_filename = 'C:/Users/ywen2/Desktop/URJC/TFG/TFG_GITHUB/ddbb/pacientes_progresores.csv'\n",
    "csv_filename = '../ddbb/pacientes_progresores.csv'\n",
    "\n",
    "with open(csv_filename, 'r') as archivo:\n",
    "    leer = csv.reader(archivo)\n",
    "    lista = list(leer)\n",
    "    lista.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Historia Progresion\n",
      "0      100220          1\n",
      "1      100257          0\n",
      "2       10045          0\n",
      "3      100505          0\n",
      "4      100598          0\n",
      "...       ...        ...\n",
      "1642    99582          0\n",
      "1643     9970          0\n",
      "1644    99828          1\n",
      "1645    99835          0\n",
      "1646     9985          0\n",
      "\n",
      "[1647 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame (lista,columns=['Historia','Progresion'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_progresores = pd.read_csv('C:/Users/ywen2/Desktop/URJC/TFG/TFG_GITHUB/ddbb/pacientes_progresores.csv').fillna(0)\n",
    "df_progresores = pd.read_csv(csv_filename).fillna(0)\n",
    "pacientes_progresores = df_progresores.iloc[:,0]\n",
    "pacientes_progresores = list(pacientes_progresores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparo ambas listas y añado a una nueva lista llamada **comparación** aquel paciente que existe en ambas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion = []\n",
    " \n",
    "for item in pacientes_independientes:\n",
    "    if item in pacientes_progresores:\n",
    "        comparacion.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creo un csv llamado df_procesados, añadiendo a la columna historia el numero de historia de aquellos pacientes que están en la lista comparación, es decir, que estan tanto en la carpeta pacientes como en el csv pacientes_progresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Historia\n",
      "0       100220\n",
      "1       100257\n",
      "2        10045\n",
      "3       100505\n",
      "4       100598\n",
      "...        ...\n",
      "1642     99582\n",
      "1643      9970\n",
      "1644     99828\n",
      "1645     99835\n",
      "1646      9985\n",
      "\n",
      "[1647 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_procesados = pd.DataFrame(comparacion, columns=[\"Historia\"])\n",
    "print(df_procesados)\n",
    "df_procesados.to_csv('pacientes_procesados.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparo el dataframe df creado por mi con el dataframe creado a partir del csv pacientes_progresores original y compruebo si coinciden todos los valores, de modo que si coinciden podemos concluir diciendo que en el csv pacientes_progresores están todos los pacientes con los que debemos trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1 = df['Historia'].astype(int)\n",
    "file2 = df_procesados['Historia'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Historia union\n",
      "0       100220  both\n",
      "1       100257  both\n",
      "2        10045  both\n",
      "3       100505  both\n",
      "4       100598  both\n",
      "...        ...   ...\n",
      "1642     99582  both\n",
      "1643      9970  both\n",
      "1644     99828  both\n",
      "1645     99835  both\n",
      "1646      9985  both\n",
      "\n",
      "[1647 rows x 2 columns]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "mergedStuff = pd.merge(file1, file2, how='inner', indicator = 'union')\n",
    "print(mergedStuff)\n",
    "\n",
    "contador = 0\n",
    "for i in mergedStuff['union']:\n",
    "    if i != 'both':\n",
    "        contador += 1\n",
    "        \n",
    "print(contador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vemos que los pacientes coinciden en ambos csv (el contador es igual a 0), por lo que podemos concluir diciendo que en el csv pacientes_progresores tenemos los pacientes con los que vamos a trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.FUNCTION TO OBTAIN IF A PATIENT IS PREDIABETIC OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pat(idd,path='../ddbb/pacientes/'):\n",
    "    \n",
    "    file = df.values.tolist()\n",
    "    paciente = pd.read_csv(path + idd+'.csv')\n",
    "    for i in file:\n",
    "        if i[0] == idd:\n",
    "            print('El paciente presenta la siguiente etiqueta:', i[1])\n",
    "    return(paciente)\n",
    "    \n",
    "    #lee fichero de ese id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El paciente presenta la siguiente etiqueta: 1\n"
     ]
    }
   ],
   "source": [
    "paciente = get_pat('100220')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.FUNCTION TO OBTAIN THE MATRICES OF PROGRESSING AND NON-PROGRESSING PATIENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Función con la que obtenemos las matrices tanto de pacientes progresores como de no progresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix():\n",
    "    progresores = []\n",
    "    no_progresores = []\n",
    "    fila = []\n",
    "    for i in df.index:\n",
    "        if df['Progresion'][i] == '1':\n",
    "             progresores.append((df['Historia'][i]))\n",
    "        else:\n",
    "            no_progresores.append((df['Historia'][i]))\n",
    "\n",
    "    row_max = 0\n",
    "    row_max_1 = 0\n",
    "    matrices = [] #list of matrices. Each list element is a matrix for one patient, with rows = reviews, cols = features\n",
    "    matrices_1 = [] #list of matrices. Each list element is a matrix for one patient, with rows = reviews, cols = features\n",
    "\n",
    "    for paciente in progresores:\n",
    "            pacientes = pd.read_csv('../ddbb/pacientes/' + paciente+'.csv',usecols = list(range(22))) #dataframe con variables.\n",
    "            #remove last column (date) --> list(range(22))\n",
    "            matrix_pat = pacientes.to_numpy() #one patient matrix\n",
    "            matrices.append(matrix_pat)\n",
    "            #print(len(matrices))\n",
    "\n",
    "            #get the maximum number of rows : it is the maximum number of reviews for a given patient.\n",
    "            filas = matrix_pat.shape[0]\n",
    "            if filas > row_max:\n",
    "                row_max = filas\n",
    "\n",
    "\n",
    "    for paciente in no_progresores:\n",
    "        pacientes = pd.read_csv('../ddbb/pacientes/' + paciente+'.csv',usecols = list(range(22)))\n",
    "            #remove last column (date)\n",
    "        matrix_pat_1 = pacientes.to_numpy() #one patient matrix\n",
    "        matrices_1.append(matrix_pat_1)\n",
    "            #print(len(matrices))\n",
    "\n",
    "            #get the maximum number of rows : it is the maiximum number of reviews for a given patient.\n",
    "        filas_1 = matrix_pat_1.shape[0]\n",
    "        if filas_1 > row_max_1:\n",
    "            row_max_1 = filas_1\n",
    "\n",
    "\n",
    "      #build complete matrix\n",
    "\n",
    "    X_progresores = np.zeros((len(matrices),row_max,22))\n",
    "    X_progresores[:,:,:] = np.nan\n",
    "\n",
    "    for i,mat in enumerate(matrices):\n",
    "        X_progresores[i,:mat.shape[0],:] = mat\n",
    "\n",
    "    X_no_progresores = np.zeros((len(matrices_1),row_max_1,22))\n",
    "    X_no_progresores[:,:,:] = np.nan\n",
    "\n",
    "    for i,mat_1 in enumerate(matrices_1):\n",
    "        X_no_progresores[i,:mat_1.shape[0],:] = mat_1\n",
    "\n",
    "    \n",
    "    \n",
    "    return X_progresores, X_no_progresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-23bc5a397b0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatriz_progresores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatriz_no_progresores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-246e734c489d>\u001b[0m in \u001b[0;36mget_matrix\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpaciente\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mno_progresores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mpacientes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../ddbb/pacientes/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpaciente\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musecols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;31m#remove last column (date)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmatrix_pat_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacientes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#one patient matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m     \"\"\"\n\u001b[0;32m    539\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "matriz_progresores, matriz_no_progresores = get_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿POR QUÉ PLOTEAMOS HASTA LA REVISIÓN 20?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.PLOTTING MEAN VALUES FOR EACH FEATURE ALONG THE REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Age','Weight','Size','IMC','Creatinine','Cystatin','HDL','LDL','Triglyciredes','GOT','GPT','GGT','Albuminuria','Ferritin','HOMA','Insulin','Blood_Glucose','Glycated-HB','PCR','Vitamin-D','TAS','TAD','Date']\n",
    "plt.figure(figsize = (15,15))\n",
    "for i in range(len(feature_names)-1):\n",
    "\n",
    "    plt.subplot(6,4,i+1)  \n",
    "    plt.plot(np.nanmean(matriz_progresores[:,:20,i],axis = 0),'k-o',linewidth = 3,label = 'Progresores')\n",
    "    plt.plot(np.nanmean(matriz_no_progresores[:,:20,i],axis = 0),'m-o',linewidth = 3,label = 'No progresores') \n",
    "    plt.title(feature_names[i])\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CUANTOS PACIENTES TIENEN MÁS DEL MAXIMO DE REVISIONES DE LOS PROGRESORES\n",
    "* TABLA/GRAFICA DE PACIENTES PROGRESORES Y NO PROGRESORES SEGUN EL NÚMERO DE REVISIONES\n",
    "\n",
    "* EN AQUELLAS GRÁFICAS QUE HAY PICOS REVISAR, Vamos a ver todas las revisiones para cada features en un jupyternotebooo diferente\n",
    "* Para todas las revisiones:PINTAR HISTOGRAMA O BOX PLOT \n",
    "* MATRIZ CON LAS MISMAS DIMENSIONES QUE MATRIZ NO/PROGRESORES. LA CREO CON TODO TRUE, EN CADA FEATURE Y REVISION QUE MODIFIQUE \n",
    "\n",
    "* PINTAR GRAFICAS SIN LOS OUTLIERS.\n",
    "\n",
    "* Número de pacientes por revisión!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.OBTAINING THE MATRIX OF INDICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MATRIZ DE ÍNDICES\n",
    "\n",
    "* Matriz *idxn* con True en las posiciones con Nan. Tiene dimensiones: $NxRxD$, donde $N =$ número de pacientes, $R = $ número de revisión, $D = $ número de características\n",
    "* Matrix *idxoutl* con True en las posiciones con outliers. Tiene dimensiones: $NxRxD$, donde $N =$ número de pacientes, $R = $ número de revisión, $D = $ número de características\n",
    "* Matriz *idx* es la matriz con Trues en la posiciones con valores válidos y False en aquellos que son NaN o bien outliers y que se tienen que imputar en su momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matrix\n",
    "idxn_no_prog = np.isnan(matriz_no_progresores) #Matriz con True en las posiciones donde hay NaN\n",
    "idxoutl_no_prog = np.empty(matriz_no_progresores.shape,'bool') #Matriz rellena de False con las mismas dimensiones que matriz_no_progresores\n",
    "idxoutl_no_prog[:] = False\n",
    "\n",
    "idxn_prog = np.isnan(matriz_progresores)\n",
    "idxoutl_prog = np.empty(matriz_progresores.shape,'bool')\n",
    "idxoutl_prog[:] = False\n",
    "\n",
    "#checking sizes \n",
    "\n",
    "print('no progresores')\n",
    "print(idxn_no_prog.shape)\n",
    "print(idxoutl_no_prog.shape)\n",
    "print(np.sum(idxn_no_prog))\n",
    "print(idxoutl_no_prog.shape)\n",
    "print(np.sum(idxoutl_no_prog))\n",
    "\n",
    "print('progresores')\n",
    "print(idxn_prog.shape)\n",
    "print(idxoutl_prog.shape)\n",
    "print(np.sum(idxn_prog))\n",
    "print(idxoutl_prog.shape)\n",
    "print(np.sum(idxoutl_prog))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_limits = [(20,90),(45,200),(120,210),(10,50),(0,4),\n",
    "                   (0,6),(10,300),(10,300),(50,750),(20,200),\n",
    "                   (20,200),(0,300),(0,3000),(15,3000),(0,60),\n",
    "                   (0,100),(40,400),(2,15),(0,200),(0,80),\n",
    "                   (90,220),(40,150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(outliers_limits)):\n",
    "    #actualizar las posiciones en las que hay outliers para cada feature\n",
    "    idxoutl_prog[:,:,i] = (matriz_progresores[:,:,i] < outliers_limits[i][0]) | (matriz_progresores[:,:,i] > outliers_limits[i][1])\n",
    "    idxoutl_no_prog[:,:,i] = (matriz_no_progresores[:,:,i] < outliers_limits[i][0]) | (matriz_no_progresores[:,:,i] > outliers_limits[i][1])\n",
    " \n",
    "# creamos matrices completas de índices para progresores y no progresores: true en las posiciones con valores reales y\n",
    "# false en valores nan o outliers\n",
    "\n",
    "idx_matrix_prog = (~idxn_prog)&(~idxoutl_prog)\n",
    "idx_matrix_no_prog = (~idxn_no_prog)&(~idxoutl_no_prog)\n",
    "\n",
    "#check sizes\n",
    "print('no progresores')\n",
    "print(idx_matrix_no_prog.shape)\n",
    "print(np.sum(idx_matrix_no_prog))\n",
    "\n",
    "print('progresores')\n",
    "print(idx_matrix_prog.shape)\n",
    "print(np.sum(idx_matrix_prog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5.REPRESENT FEATURES BASED ON THE NUMBER OF REVIEWS WITHOUT OUTLIERS AND NAN\n",
    "\n",
    "A continuación representamos de forma conjunta el valor medio de los pacientes para cada revisión (separados por features), sin incluir los valores considerados como NaN ni outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mean value per review and feature\n",
    "idx_matrix_prog[:,0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Age','Weight','Size','IMC','Creatinine','Cystatin','HDL','LDL','Triglyciredes','GOT','GPT','GGT','Albuminuria','Ferritin','HOMA','Insulin','Blood_Glucose','Glycated-HB','PCR','Vitamin-D','TAS','TAD','Date']\n",
    "plt.figure(figsize = (15,15))\n",
    "\n",
    "\n",
    "for i in range(len(feature_names)-1):\n",
    "\n",
    "    m_rev_prog = []\n",
    "    m_rev_no_prog = []\n",
    "    \n",
    "    #mean value per review\n",
    "    \n",
    "    for j in range(13): #13 review seems to be the best option (A PARTIR DE 13 HAY POCOS DATOS)\n",
    "        aux_m = np.mean(matriz_progresores[idx_matrix_prog[:,j,i],j,i],axis = 0)\n",
    "        \n",
    "        #Miro el primer valor de la feature de cada paciente según vamos iterando y \n",
    "        #creo un lista con ese primer valor de cada paciente (en este caso 132) y hago la media de esa lista para saber \n",
    "        #la feature media en cada revisión\n",
    "        #idx_matrix_prog[:,j,i] me indica que valores de matriz_progresores son valores reales (ni outliers ni NaN)\n",
    "        \n",
    "        #EJEMPLO: Edad de los 132 pacientes en la primera revisión y así sucesivamente hasta las 13 revisiones (13 listas\n",
    "        #con 132 valores de cada feature) ,hago la media de esos 132 valores\n",
    "        m_rev_prog.append(aux_m)\n",
    "        \n",
    "        aux_m_n = np.mean(matriz_no_progresores[idx_matrix_no_prog[:,j,i],j,i],axis = 0)\n",
    "        m_rev_no_prog.append(aux_m_n)\n",
    "    \n",
    "\n",
    "    plt.subplot(6,4,i+1)  \n",
    "    plt.plot(m_rev_prog,'k-o',linewidth = 3,label = 'Progresores')\n",
    "    plt.plot(m_rev_no_prog,'m-o',linewidth = 3,label = 'No progresores') \n",
    "    plt.title(feature_names[i])\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SPLIT TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. SHUFFLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico shuffle para aleatorizar el orden de los pacientes, manteniendo las revisiones y las features como originalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pat_prog = list(range(132))\n",
    "np.random.shuffle(random_pat_prog)\n",
    "matriz_progresores_shuffle = matriz_progresores[random_pat_prog,:,:]\n",
    "\n",
    "matriz_progresores_train = matriz_progresores_shuffle[:105,:13,:]\n",
    "labels_train = [1]*np.shape(matriz_progresores_train)[0]\n",
    "\n",
    "matriz_progresores_test = matriz_progresores_shuffle[105:,:13,:]\n",
    "labels_test = [1]*np.shape(matriz_progresores_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pat_no_prog = list(range(1515))\n",
    "np.random.shuffle(random_pat_no_prog)\n",
    "matriz_no_progresores_shuffle = matriz_no_progresores[random_pat_no_prog,:,:]\n",
    "\n",
    "matriz_no_progresores_train = matriz_no_progresores_shuffle[:1212,:13,:]\n",
    "labels_train = labels_train + [0]*np.shape(matriz_no_progresores_train)[0]\n",
    "\n",
    "matriz_no_progresores_test = matriz_no_progresores_shuffle[1212:,:13,:]\n",
    "labels_test = labels_test + [0]*np.shape(matriz_no_progresores_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matriz_progresores_train.shape)\n",
    "print(matriz_progresores_test.shape)\n",
    "print(matriz_no_progresores_train.shape)\n",
    "print(matriz_no_progresores_test.shape)\n",
    "print(len(labels_train))\n",
    "print(len(labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo 132 pacientes progresores, el 80% serían 105 pacientes y el 20% restante 27 pacientes\n",
    "\n",
    "Tengo 1515 pacientes progresores, el 80% serían 1212 pacientes y el 20% restante 303 pacientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número total de pacientes es 1647, quiero el % de progresores y no progresores.\n",
    "\n",
    "% Progresores = 0.080\n",
    "\n",
    "% No progresores = 0.92\n",
    "\n",
    "Ahora separo en train y test, quiero mantener la proporción por lo que dentro de train quiero un 0.080% de progresores y un 0.92% de no progresores e igual para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto_train = np.concatenate((matriz_progresores_train , matriz_no_progresores_train), axis=0) \n",
    "conjunto_test = np.concatenate((matriz_progresores_test, matriz_no_progresores_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos labels a array para poder trabajar con ellas. Hacemos un shuffle a conjunto train y conjunto test ya que estan ordenadas (primero los progresores y luego los no progresores), hacemos lo mismo con las labels. Aplicamos el mismo random por lo que cada paciente continuara teniendo asociada su etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.array(labels_train)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pat_prog = list(range(conjunto_train.shape[0]))\n",
    "np.random.shuffle(random_pat_prog)\n",
    "conjunto_train_shuffle = conjunto_train[random_pat_prog,:,:]\n",
    "labels_train_shuffle = labels_train[random_pat_prog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_train_shuffle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pat_prog = list(range(conjunto_test.shape[0]))\n",
    "np.random.shuffle(random_pat_prog)\n",
    "conjunto_test_shuffle = conjunto_test[random_pat_prog,:,:]\n",
    "labels_test_shuffle = labels_test[random_pat_prog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_test_shuffle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Conjunto_train', conjunto_train_shuffle)\n",
    "np.save('Conjunto_test', conjunto_test_shuffle)\n",
    "np.save('Labels_train', labels_train_shuffle)\n",
    "np.save('Labels_test', labels_test_shuffle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
